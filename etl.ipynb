{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe499d58",
   "metadata": {},
   "source": [
    "## Overview of the ETL Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebdc49",
   "metadata": {},
   "source": [
    "##### This notebook walks through an ETL process, which stands for Extract, Transform, and Load. Youâ€™ll see how to bring in different types of data, tidy them up, create new useful information, and save the cleaned results for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431b595",
   "metadata": {},
   "source": [
    "### Data Collection (Extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d36f8f",
   "metadata": {},
   "source": [
    "##### First, we gather data from several sources including CSV files, JSON files, XML files, and databases. Learning to fetch data from various formats is crucial in real-world data projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1104cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(r'N:\\ETL\\raw_files'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9747ff2",
   "metadata": {},
   "source": [
    "#### Getting to Know Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a179afe",
   "metadata": {},
   "source": [
    "##### We inspect the first few rows and check for empty or missing values to better understand what problems the dataset might have. This helps us decide how to clean and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects = pd.read_csv('N:/ETL/raw_files/population_data.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb2d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3485161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a65b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = pd.read_csv('N:/ETL/raw_files/population_data.csv')\n",
    "df_population.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cf813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8607ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = df_population.drop('Unnamed: 62', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population[df_population.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff00b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lines(n, file_name):\n",
    "    f = open(file_name)\n",
    "    for i in range(n):\n",
    "        print(f.readline())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_lines(1, 'N:/ETL/raw_files/population_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = pd.read_json('N:/ETL/raw_files/population_data.json',orient='records')\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ed703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read in the JSON file\n",
    "\n",
    "with open('N:/ETL/raw_files/population_data.json') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# read the first record in the JSON file\n",
    "print(json_data[0])\n",
    "print('\\n')\n",
    "\n",
    "# show that JSON data is essentially a dictionary\n",
    "print(json_data[0]['Country Name'])\n",
    "print(json_data[0]['Country Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_lines(15, 'N:/ETL/raw_files/population_data.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07879157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('N:/ETL/raw_files/population_data.xml') as fp:\n",
    "    soup = BeautifulSoup(fp, \"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# use the find_all method to get all record tags in the document\n",
    "for record in soup.find_all('record'):\n",
    "    # use the find_all method to get all fields in each record\n",
    "    i += 1\n",
    "    for record in record.find_all('field'):\n",
    "        print(record['name'], ': ' , record.text)\n",
    "    print()\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "#connection to the database \n",
    "conn = sqlite3.connect('N:/ETL/raw_files/population_data.db')\n",
    "\n",
    "#run a query\n",
    "pd.read_sql('SELECT * FROM population_data', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13632f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('SELECT \"Country_Name\", \"Country_Code\", \"1960\" FROM population_data', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://api.worldbank.org/v2/countries/br;cn;us;de/indicators/SP.POP.TOTL/?format=json&per_page=1000'\n",
    "r = requests.get(url)  # Make sure this line is executed first\n",
    "\n",
    "r = requests.get(url)\n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://api.worldbank.org/v2/country/CH/indicator/SP.POP.TOTL/?format=json&date=1995:2001'\n",
    "\n",
    "# TODO: send the request\n",
    "r = requests.get(url)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d421a1",
   "metadata": {},
   "source": [
    "### Combining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd545fd",
   "metadata": {},
   "source": [
    "#### Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f9145",
   "metadata": {},
   "source": [
    "##### Cleaning involves fixing errors, removing unnecessary information, and dealing with missing or repeated values. Properly prepared data helps make sure our analysis is reliable and clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16702d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('N:/ETL/raw_files/rural_population_percent.csv')\n",
    "for i in range(10):\n",
    "    line = f.readline()\n",
    "    print('line: ', i, line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rural = pd.read_csv('N:/ETL/raw_files/rural_population_percent.csv',skiprows=4)\n",
    "df_rural.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('N:/ETL/raw_files/electricity_access_percent.csv')\n",
    "for i in range(10):\n",
    "    line = f.readline()\n",
    "    print('line: ', i, line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electricity = pd.read_csv('N:/ETL/raw_files/electricity_access_percent.csv',skiprows=4)\n",
    "df_electricity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1394d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rural.drop(['Unnamed: 62'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f41181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electricity.drop(['Unnamed: 62'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rural.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rural, df_electricity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca47ede",
   "metadata": {},
   "source": [
    "#### Dealing with Missing Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb11ed",
   "metadata": {},
   "source": [
    "##### When data is incomplete, we fill in the blanks using methods like averaging available data or copying nearby values. This helps prevent mistakes during calculations or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator = pd.read_csv('N:/ETL/raw_files/population_data.csv')\n",
    "df_indicator.drop(['Unnamed: 62'], axis=1, inplace=True)\n",
    "\n",
    "# read in the projects data set with all columns type string\n",
    "df_projects = pd.read_csv('N:/ETL/raw_files/projects_data.csv', dtype=str)\n",
    "df_projects.drop(['Unnamed: 56'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator[['Country Name', 'Country Code']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['countryname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f23f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['Official Country Name'] = df_projects['countryname'].str.split(';').str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycountry\n",
    "from pycountry import countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce31e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.get(name='Spain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43db959",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.lookup('Kingdom of Spain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5370202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "country_not_found = [] # stores countries not found in the pycountry library\n",
    "project_country_abbrev_dict = defaultdict(str) # set up an empty dictionary of string values\n",
    "\n",
    "# iterate through the country names in df_projects. \n",
    "# Create a dictionary mapping the country name to the alpha_3 ISO code\n",
    "for country in df_projects['Official Country Name'].drop_duplicates().sort_values():\n",
    "    try: \n",
    "        # look up the country name in the pycountry library\n",
    "        # store the country name as the dictionary key and the ISO-3 code as the value\n",
    "        project_country_abbrev_dict[country] = countries.lookup(country).alpha_3\n",
    "    except:\n",
    "        # If the country name is not in the pycountry library, then print out the country name\n",
    "        # And store the results in the country_not_found list\n",
    "        print(country, ' not found')\n",
    "        country_not_found.append(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bff8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_countries = df_indicator[['Country Name', 'Country Code']].drop_duplicates().sort_values(by='Country Name')\n",
    "\n",
    "for country in country_not_found:\n",
    "    if country in indicator_countries['Country Name'].tolist():\n",
    "        print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_not_found_mapping = {'Co-operative Republic of Guyana': 'GUY',\n",
    "             'Commonwealth of Australia':'AUS',\n",
    "             'Democratic Republic of Sao Tome and Prin':'STP',\n",
    "             'Democratic Republic of the Congo':'COD',\n",
    "             'Democratic Socialist Republic of Sri Lan':'LKA',\n",
    "             'East Asia and Pacific':'EAS',\n",
    "             'Europe and Central Asia': 'ECS',\n",
    "             'Islamic  Republic of Afghanistan':'AFG',\n",
    "             'Latin America':'LCN',\n",
    "              'Caribbean':'LCN',\n",
    "             'Macedonia':'MKD',\n",
    "             'Middle East and North Africa':'MEA',\n",
    "             'Oriental Republic of Uruguay':'URY',\n",
    "             'Republic of Congo':'COG',\n",
    "             \"Republic of Cote d'Ivoire\":'CIV',\n",
    "             'Republic of Korea':'KOR',\n",
    "             'Republic of Niger':'NER',\n",
    "             'Republic of Kosovo':'XKX',\n",
    "             'Republic of Rwanda':'RWA',\n",
    "              'Republic of The Gambia':'GMB',\n",
    "              'Republic of Togo':'TGO',\n",
    "              'Republic of the Union of Myanmar':'MMR',\n",
    "              'Republica Bolivariana de Venezuela':'VEN',\n",
    "              'Sint Maarten':'SXM',\n",
    "              \"Socialist People's Libyan Arab Jamahiriy\":'LBY',\n",
    "              'Socialist Republic of Vietnam':'VNM',\n",
    "              'Somali Democratic Republic':'SOM',\n",
    "              'South Asia':'SAS',\n",
    "              'St. Kitts and Nevis':'KNA',\n",
    "              'St. Lucia':'LCA',\n",
    "              'St. Vincent and the Grenadines':'VCT',\n",
    "              'State of Eritrea':'ERI',\n",
    "              'The Independent State of Papua New Guine':'PNG',\n",
    "              'West Bank and Gaza':'PSE',\n",
    "              'World':'WLD'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_country_abbrev_dict.update(country_not_found_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['Country Code'] = df_projects['Official Country Name'].apply(lambda x: project_country_abbrev_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa899e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_projects[df_projects['Country Code'] == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9e330",
   "metadata": {},
   "source": [
    "#### data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ed028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects = pd.read_csv('N:/ETL/raw_files/projects_data.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd39aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in the population data and drop the final column\n",
    "df_indicator = pd.read_csv('N:/ETL/raw_files/population_data.csv')\n",
    "df_indicator.drop(['Unnamed: 62'], axis=1, inplace=True)\n",
    "\n",
    "# read in the projects data set with all columns type string\n",
    "df_projects = pd.read_csv('N:/ETL/raw_files/projects_data.csv', dtype=str)\n",
    "df_projects.drop(['Unnamed: 56'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepcol = ['Country Name']\n",
    "for i in range(1960, 2018, 1):\n",
    "    keepcol.append(str(i))\n",
    "\n",
    "# In the df_nafta variable, store a data frame that only contains the rows for \n",
    "#      Canada, United States, and Mexico.\n",
    "df_nafta = df_indicator[(df_indicator['Country Name'] == 'Canada') | \n",
    "             (df_indicator['Country Name'] == 'United States') | \n",
    "            (df_indicator['Country Name'] == 'Mexico')].iloc[:,]\n",
    "\n",
    "\n",
    "# Calculate the sum of the values in each column in order to find the total population by year.\n",
    "# You can use the keepcol variable if you want to control which columns get outputted\n",
    "df_nafta.sum(axis=0)[keepcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects[['totalamt', 'lendprojectcost']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0203c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['totalamt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc0452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['totalamt'] = pd.to_numeric(df_projects['totalamt'].str.replace(',',\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8683722",
   "metadata": {},
   "source": [
    "#### Working with Time and Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81ce1b",
   "metadata": {},
   "source": [
    "##### We convert date-like text into special formats that let us easily extract parts like the year, month, and weekday, which helps in analyzing changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c48461",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_date = pd.to_datetime('January 1st, 2017')\n",
    "parsed_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_date.month\n",
    "parsed_date.year\n",
    "parsed_date.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cb8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_date = pd.to_datetime('5/3/2017 5:30')\n",
    "parsed_date.month\n",
    "parsed_date = pd.to_datetime('3/5/2017 5:30', format='%d/%m/%Y %H:%M')\n",
    "parsed_date.month\n",
    "parsed_date = pd.to_datetime('5/3/2017 5:30', format='%m/%d/%Y %H:%M')\n",
    "parsed_date.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects = pd.read_csv('N:/ETL/raw_files/projects_data.csv', dtype=str)\n",
    "df_projects.drop(['Unnamed: 56'], axis=1, inplace=True)\n",
    "df_projects.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6932a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects.head(15)[['boardapprovaldate', 'board_approval_month', 'closingdate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d33db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['boardapprovaldate'] = pd.to_datetime(df_projects['boardapprovaldate'])\n",
    "df_projects['closingdate'] = pd.to_datetime(df_projects['closingdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['boardapprovaldate'].dt.second\n",
    "# Run this code cell to see the output\n",
    "df_projects['boardapprovaldate'].dt.month\n",
    "# Run this code to see the output\n",
    "# weekday represents the day of the week from 0 (Monday) to 6 (Sunday).\n",
    "df_projects['boardapprovaldate'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['approvalyear'] = df_projects['boardapprovaldate'].dt.year\n",
    "df_projects['approvalday'] = df_projects['boardapprovaldate'].dt.day\n",
    "df_projects['approvalweekday'] = df_projects['boardapprovaldate'].dt.weekday\n",
    "df_projects['closingyear'] = df_projects['closingdate'].dt.year\n",
    "df_projects['closingday'] = df_projects['closingdate'].dt.day\n",
    "df_projects['closingweekday'] = df_projects['closingdate'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('N:/ETL/raw_files/population_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodings.aliases import aliases\n",
    "\n",
    "alias_values = set(aliases.values())\n",
    "\n",
    "for encoding in set(aliases.values()):\n",
    "    try:\n",
    "        df=pd.read_csv(\"mystery.csv\", encoding=encoding)\n",
    "        print('successful', encoding)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2bb647",
   "metadata": {},
   "source": [
    "#### imputing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=4)\n",
    "df.drop('Unnamed: 62', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e80cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "# Run this code cell to check how many null values are in the data set\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c9641",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# put the data set into long form instead of wide\n",
    "df_melt = pd.melt(df, id_vars=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'], var_name='year', value_name='GDP')\n",
    "\n",
    "# convert year to a date time\n",
    "df_melt['year'] = pd.to_datetime(df_melt['year'])\n",
    "\n",
    "def plot_results(column_name):\n",
    "    # plot the results for Afghanistan, Albania, and Honduras\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "    df_melt[(df_melt['Country Name'] == 'Afghanistan') | \n",
    "            (df_melt['Country Name'] == 'Albania') | \n",
    "            (df_melt['Country Name'] == 'Honduras')].groupby('Country Name').plot('year', column_name, legend=True, ax=ax)\n",
    "    ax.legend(labels=['Afghanistan', 'Albania', 'Honduras'])\n",
    "    \n",
    "plot_results('GDP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db15cf9",
   "metadata": {},
   "source": [
    "##### excersixe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt['GDP_filled'] = df_melt.groupby('Country Name')['GDP'].transform(lambda x: x.fillna(x.mean()))\n",
    "# Plot the results\n",
    "plot_results('GDP_filled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff06a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt['GDP_ffill'] = df_melt.sort_values('year').groupby('Country Name')['GDP'].fillna(method='ffill')\n",
    "# plot the results\n",
    "plot_results('GDP_ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ad2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_melt['GDP_bfill'] = df_melt.sort_values('year').groupby('Country Name')['GDP'].fillna(method='bfill')\n",
    "plot_results('GDP_bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a373f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forward fill and backward fill on the GDP data\n",
    "df_melt['GDP_ff_bf'] = df_melt.sort_values('year').groupby('Country Name')['GDP'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Check if any GDP values are null\n",
    "df_melt['GDP_ff_bf'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a119abe8",
   "metadata": {},
   "source": [
    "### Duplicate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56529b1",
   "metadata": {},
   "source": [
    "##### Removing Repeated Entries Duplicate data can skew our results, so we search for and delete any repeated rows to get accurate insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a82a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = pd.read_csv('N:/ETL/raw_files/projects_data.csv', dtype=str)\n",
    "projects.drop('Unnamed: 56', axis=1, inplace=True)\n",
    "projects['totalamt'] = pd.to_numeric(projects['totalamt'].str.replace(',', ''))\n",
    "projects['countryname'] = projects['countryname'].str.split(';', expand=True)[0]\n",
    "projects['boardapprovaldate'] = pd.to_datetime(projects['boardapprovaldate'])\n",
    "\n",
    "# filter the data frame for projects over 1 billion dollars\n",
    "\n",
    "# count the number of unique countries in the results\n",
    "\n",
    "projects[projects['totalamt'] > 1000000000]['countryname'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26a2ae",
   "metadata": {},
   "source": [
    "##### Converting Categories to Numbers (Dummy Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ca8e8",
   "metadata": {},
   "source": [
    "##### Text categories such as sectors or regions are turned into numerical columns of 0s and 1s. This lets computers handle categorical data in calculations and machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = pd.read_csv('N:/ETL/raw_files/projects_data.csv', dtype=str)\n",
    "projects.drop('Unnamed: 56', axis=1, inplace=True)\n",
    "projects['totalamt'] = pd.to_numeric(projects['totalamt'].str.replace(',', ''))\n",
    "projects['countryname'] = projects['countryname'].str.split(';', expand=True)[0]\n",
    "projects['boardapprovaldate'] = pd.to_datetime(projects['boardapprovaldate'])\n",
    "\n",
    "# keep the project name, lending, sector and theme data\n",
    "sector = projects.copy()\n",
    "sector = sector[['project_name', 'lendinginstr', 'sector1', 'sector2', 'sector3', 'sector4', 'sector5', 'sector',\n",
    "          'mjsector1', 'mjsector2', 'mjsector3', 'mjsector4', 'mjsector5',\n",
    "          'mjsector', 'theme1', 'theme2', 'theme3', 'theme4', 'theme5', 'theme ',\n",
    "          'goal', 'financier', 'mjtheme1name', 'mjtheme2name', 'mjtheme3name',\n",
    "          'mjtheme4name', 'mjtheme5name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38395057",
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * sector.isnull().sum() / sector.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniquesectors1 = sector['sector1'].sort_values().unique()\n",
    "uniquesectors1\n",
    "# run this code cell to see the number of unique values\n",
    "print('Number of unique values in sector1:', len(uniquesectors1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dabaff",
   "metadata": {},
   "source": [
    "#### replace() methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector['sector1'] = sector['sector1'].replace('!$!0', np.nan)\n",
    "\n",
    "# TODO: In the sector1 variable, remove the last 10 or 11 characters from the sector1 variable.\n",
    "# HINT: There is more than one way to do this including the replace method\n",
    "# HINT: You can use a regex expression '!.+'\n",
    "# That regex expression looks for a string with an exclamation\n",
    "# point followed by one or more characters\n",
    "\n",
    "sector['sector1'] = sector['sector1'].replace('!.+', '', regex=True)\n",
    "\n",
    "# TODO: Remove the string '(Historic)' from the sector1 variable\n",
    "# HINT: You can use the replace method\n",
    "sector['sector1'] = sector['sector1'].replace('^(\\(Historic\\))', '', regex=True)\n",
    "\n",
    "print('Number of unique sectors after cleaning:', len(list(sector['sector1'].unique())))\n",
    "print('Percentage of null values after cleaning:', 100 * sector['sector1'].isnull().sum() / sector['sector1'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.DataFrame(pd.get_dummies(sector['sector1']))\n",
    "\n",
    "#  Filter the projects data for the totalamt, the year from boardapprovaldate, and the dummy variables\n",
    "projects['year'] = projects['boardapprovaldate'].dt.year\n",
    "df = projects[['totalamt','year']]\n",
    "df_final = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29977ae5",
   "metadata": {},
   "source": [
    "#### Identifying and Visualizing Unusual Data Points (Outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af421e4",
   "metadata": {},
   "source": [
    "##### Some values are much higher or lower than the majority. We use statistical rules to find these outliers and visualize them using boxplots to understand their impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the datasets and do basic wrangling\n",
    "gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=4)\n",
    "gdp.drop([col for col in ['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'] if col in gdp.columns], inplace=True, axis=1)\n",
    "\n",
    "population = pd.read_csv('N:/ETL/raw_files/population_data.csv')\n",
    "population.drop([col for col in ['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'] if col in population.columns], inplace=True, axis=1)\n",
    "\n",
    "# Check actual column names\n",
    "print(\"GDP columns:\", gdp.columns)\n",
    "print(\"Population columns:\", population.columns)\n",
    "\n",
    "# Use the correct column name for id_vars\n",
    "# Find the correct column name for country in GDP and population datasets\n",
    "country_col_gdp = next((col for col in gdp.columns if 'Country Name' in col), None)\n",
    "country_col_population = next((col for col in population.columns if 'Country Name' in col), None)\n",
    "\n",
    "if country_col_gdp is None or country_col_population is None:\n",
    "    raise ValueError(\"Could not find 'Country Name' column in one of the datasets. Actual columns: GDP: {}, Population: {}\".format(gdp.columns, population.columns))\n",
    "\n",
    "# Reshape the data sets so that they are in long format\n",
    "gdp_melt = gdp.melt(id_vars=[country_col_gdp],\n",
    "                    var_name='year',\n",
    "                    value_name='gdp')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing gdp values\n",
    "gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby('Country Name')['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "population_melt = population.melt(id_vars=['Country Name'],\n",
    "                                  var_name='year',\n",
    "                                  value_name='population')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing population values\n",
    "population_melt['population'] = population_melt.sort_values('year').groupby('Country Name')['population'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Merge the population and gdp data together into one data frame\n",
    "df_country = gdp_melt.merge(population_melt, on=('Country Name', 'year'))\n",
    "\n",
    "# Filter data for the year 2016\n",
    "df_2016 = df_country[df_country['year'] == '2016']\n",
    "\n",
    "# See what the data looks like\n",
    "df_2016.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad10694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Apply Tukey Rule to find outliers in population data for 2016\n",
    "def tukey_outlier_analysis(data, column):\n",
    "    \"\"\"\n",
    "    Apply Tukey Rule to identify outliers\n",
    "    \"\"\"\n",
    "    print(f\"Tukey Rule Outlier Analysis for {column.title()} - 2016\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Find the first quartile (Q1 - 25th percentile)\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    print(f\"First Quartile (Q1): {Q1:,.0f}\")\n",
    "    \n",
    "    # Step 2: Find the third quartile (Q3 - 75th percentile)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    print(f\"Third Quartile (Q3): {Q3:,.0f}\")\n",
    "    \n",
    "    # Step 3: Calculate the inter-quartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    print(f\"Inter-Quartile Range (IQR): {IQR:,.0f}\")\n",
    "    \n",
    "    # Step 4 & 5: Calculate outlier bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    print(f\"\\nOutlier Bounds:\")\n",
    "    print(f\"Lower Bound (Q1 - 1.5 * IQR): {lower_bound:,.0f}\")\n",
    "    print(f\"Upper Bound (Q3 + 1.5 * IQR): {upper_bound:,.0f}\")\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers_lower = data[data[column] < lower_bound]\n",
    "    outliers_upper = data[data[column] > upper_bound]\n",
    "    all_outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    \n",
    "    print(f\"\\nOutlier Results:\")\n",
    "    print(f\"Total number of outliers: {len(all_outliers)}\")\n",
    "    print(f\"Lower outliers (< {lower_bound:,.0f}): {len(outliers_lower)}\")\n",
    "    print(f\"Upper outliers (> {upper_bound:,.0f}): {len(outliers_upper)}\")\n",
    "    \n",
    "    # Display outlier countries\n",
    "    if len(all_outliers) > 0:\n",
    "        print(f\"\\nCountries identified as outliers:\")\n",
    "        print(\"-\" * 40)\n",
    "        for idx, row in all_outliers.sort_values(column, ascending=False).iterrows():\n",
    "            outlier_type = \"Upper\" if row[column] > upper_bound else \"Lower\"\n",
    "            print(f\"{row['Country Name']}: {row[column]:,.0f} ({outlier_type})\")\n",
    "    else:\n",
    "        print(\"No outliers found.\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nSummary Statistics for {column.title()}:\")\n",
    "    print(f\"Minimum: {data[column].min():,.0f}\")\n",
    "    print(f\"Maximum: {data[column].max():,.0f}\")\n",
    "    print(f\"Mean: {data[column].mean():,.0f}\")\n",
    "    print(f\"Median: {data[column].median():,.0f}\")\n",
    "    print(f\"Standard Deviation: {data[column].std():,.0f}\")\n",
    "    \n",
    "    return all_outliers\n",
    "\n",
    "# Apply Tukey rule to population data\n",
    "population_outliers = tukey_outlier_analysis(df_2016, 'population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67145f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_boxplot_with_outliers(data, column, title):\n",
    "    \"\"\"Create boxplot and label outliers with country names\"\"\"\n",
    "    \n",
    "    # Calculate quartiles and IQR\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define outlier bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    \n",
    "    # Create the boxplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Create boxplot\n",
    "    box_plot = ax.boxplot(data[column].dropna(), patch_artist=True)\n",
    "    \n",
    "    # Color the box\n",
    "    box_plot['boxes'][0].set_facecolor('lightblue')\n",
    "    box_plot['boxes'][0].set_alpha(0.7)\n",
    "    \n",
    "    # Add outlier points with labels\n",
    "    for idx, row in outliers.iterrows():\n",
    "        ax.plot(1, row[column], 'ro', markersize=8)  # Red dots for outliers\n",
    "        ax.annotate(row['Country Name'], \n",
    "                   xy=(1, row[column]), \n",
    "                   xytext=(1.1, row[column]),\n",
    "                   fontsize=9,\n",
    "                   ha='left',\n",
    "                   va='center',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "                   arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "    ax.set_title(f'{title} - 2016', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(column.title(), fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print outlier information\n",
    "    print(f\"\\n{title} Outliers:\")\n",
    "    print(\"-\" * 40)\n",
    "    for idx, row in outliers.iterrows():\n",
    "        print(f\"{row['Country Name']}: {row[column]:,.0f}\")\n",
    "\n",
    "# Create boxplots with outlier labels\n",
    "plot_boxplot_with_outliers(df_2016, 'population', 'Population Distribution')\n",
    "plot_boxplot_with_outliers(df_2016, 'gdp', 'GDP Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2016 = df_2016[['Country Name','population']]\n",
    "\n",
    "# Calculate the first quartile of the population values for 2016\n",
    "# HINT: you can use the pandas quantile method \n",
    "Q1 = population_2016['population'].quantile(0.25)\n",
    "\n",
    "# Calculate the third quartile of the population values for 2016\n",
    "Q3 = population_2016['population'].quantile(0.75)\n",
    "\n",
    "# Calculate the interquartile range Q3 - Q1\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the maximum value and minimum values according to the Tukey rule\n",
    "# max_value is Q3 + 1.5 * IQR while min_value is Q1 - 1.5 * IQR\n",
    "max_value = Q3 + 1.5 * IQR\n",
    "min_value = Q1 - 1.5 * IQR\n",
    "\n",
    "# filter the population_2016 data for population values that are greater than max_value or less than min_value\n",
    "population_outliers = population_2016[(population_2016['population'] > max_value) | (population_2016['population'] < min_value)]\n",
    "population_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_countries = ['World',\n",
    " 'High income',\n",
    " 'OECD members',\n",
    " 'Post-demographic dividend',\n",
    " 'IDA & IBRD total',\n",
    " 'Low & middle income',\n",
    " 'Middle income',\n",
    " 'IBRD only',\n",
    " 'East Asia & Pacific',\n",
    " 'Europe & Central Asia',\n",
    " 'North America',\n",
    " 'Upper middle income',\n",
    " 'Late-demographic dividend',\n",
    " 'European Union',\n",
    " 'East Asia & Pacific (excluding high income)',\n",
    " 'East Asia & Pacific (IDA & IBRD countries)',\n",
    " 'Euro area',\n",
    " 'Early-demographic dividend',\n",
    " 'Lower middle income',\n",
    " 'Latin America & Caribbean',\n",
    " 'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    " 'Latin America & Caribbean (excluding high income)',\n",
    " 'Europe & Central Asia (IDA & IBRD countries)',\n",
    " 'Middle East & North Africa',\n",
    " 'Europe & Central Asia (excluding high income)',\n",
    " 'South Asia (IDA & IBRD)',\n",
    " 'South Asia',\n",
    " 'Arab World',\n",
    " 'IDA total',\n",
    " 'Sub-Saharan Africa',\n",
    " 'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    " 'Sub-Saharan Africa (excluding high income)',\n",
    " 'Middle East & North Africa (excluding high income)',\n",
    " 'Middle East & North Africa (IDA & IBRD countries)',\n",
    " 'Central Europe and the Baltics',\n",
    " 'Pre-demographic dividend',\n",
    " 'IDA only',\n",
    " 'Least developed countries: UN classification',\n",
    " 'IDA blend',\n",
    " 'Fragile and conflict affected situations',\n",
    " 'Heavily indebted poor countries (HIPC)',\n",
    " 'Low income',\n",
    " 'Small states',\n",
    " 'Other small states',\n",
    " 'Not classified',\n",
    " 'Caribbean small states',\n",
    " 'Pacific island small states']\n",
    "\n",
    "# remove non countries from the data\n",
    "df_2016 = df_2016[~df_2016['Country Name'].isin(non_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7810bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2016 = df_2016[['Country Name','population']]\n",
    "\n",
    "# Calculate the first quartile of the population values\n",
    "# HINT: you can use the pandas quantile method \n",
    "Q1 = population_2016['population'].quantile(0.25)\n",
    "\n",
    "# Calculate the third quartile of the population values\n",
    "Q3 = population_2016['population'].quantile(0.75)\n",
    "\n",
    "# Calculate the interquartile range Q3 - Q1\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the maximum value and minimum values according to the Tukey rule\n",
    "# max_value is Q3 + 1.5 * IQR while min_value is Q1 - 1.5 * IQR\n",
    "max_value = Q3 + 1.5 * IQR\n",
    "min_value = Q1 - 1.5 * IQR\n",
    "\n",
    "# filter the population_2016 data for population values that are greater than max_value or less than min_value\n",
    "population_outliers = population_2016[(population_2016['population'] > max_value) | (population_2016['population'] < min_value)]\n",
    "population_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8829f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for the year 2016 and put the results in the population_2016 variable. You only need\n",
    "# to keep the Country Name and population columns\n",
    "gdp_2016 = df_2016[['Country Name','gdp']]\n",
    "\n",
    "# Calculate the first quartile of the population values\n",
    "# HINT: you can use the pandas quantile method \n",
    "Q1 = gdp_2016['gdp'].quantile(0.25)\n",
    "\n",
    "# Calculate the third quartile of the population values\n",
    "Q3 = gdp_2016['gdp'].quantile(0.75)\n",
    "\n",
    "# Calculate the interquartile range Q3 - Q1\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the maximum value and minimum values according to the Tukey rule\n",
    "# max_value is Q3 + 1.5 * IQR while min_value is Q1 - 1.5 * IQR\n",
    "max_value = Q3 + 1.5 * IQR\n",
    "min_value = Q1 - 1.5 * IQR\n",
    "\n",
    "# filter the population_2016 data for population values that are greater than max_value or less than min_value\n",
    "gdp_outliers = gdp_2016[(gdp_2016['gdp'] > max_value) | (gdp_2016['gdp'] < min_value)]\n",
    "gdp_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find country names that are in both the population_outliers and the gdp_outliers \n",
    "# HINT: you can use the pandas intersection() method and python set() and list() methods\n",
    "\n",
    "list(set(population_outliers['Country Name']).intersection(gdp_outliers['Country Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530cb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(set(population_outliers['Country Name']) - set(gdp_outliers['Country Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec643593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(set(gdp_outliers['Country Name']) - set(population_outliers['Country Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f852e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(df_2016['population'])\n",
    "y = list(df_2016['gdp'])\n",
    "text = df_2016['Country Name']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.scatter(x, y)\n",
    "plt.title('GDP vs Population')\n",
    "plt.xlabel('population')\n",
    "plt.ylabel('GDP')\n",
    "for i, txt in enumerate(text):\n",
    "    ax.annotate(txt, (x[i],y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_large = (df_2016['Country Name'] != 'United States') & (df_2016['Country Name'] != 'India') & (df_2016['Country Name'] != 'China')\n",
    "x = list(df_2016[df_no_large]['population'])\n",
    "y = list(df_2016[df_no_large]['gdp'])\n",
    "text = df_2016[df_no_large]['Country Name']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.scatter(x, y)\n",
    "plt.title('GDP vs Population')\n",
    "plt.xlabel('population')\n",
    "plt.ylabel('GDP')\n",
    "for i, txt in enumerate(text):\n",
    "    ax.annotate(txt, (x[i],y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Check if df_2016 is empty before fitting the model\n",
    "if df_2016.shape[0] > 0:\n",
    "\tmodel = LinearRegression()\n",
    "\tmodel.fit(df_2016['population'].values.reshape(-1, 1), df_2016['gdp'].values.reshape(-1, 1))\n",
    "\n",
    "\t# plot the data along with predictions from the linear regression model\n",
    "\tinputs = np.linspace(1, 2000000000, num=50)\n",
    "\tpredictions = model.predict(inputs.reshape(-1,1))\n",
    "\n",
    "\tdf_2016.plot('population', 'gdp', kind='scatter')\n",
    "\tplt.plot(inputs, predictions)\n",
    "else:\n",
    "\tprint(\"df_2016 is empty. Cannot fit LinearRegression model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016[df_2016['Country Name'] != 'United States'].plot('population', 'gdp', kind='scatter')\n",
    "# plt.plot(inputs, predictions)\n",
    "model.fit(df_2016[df_2016['Country Name'] != 'United States']['population'].values.reshape(-1, 1), \n",
    "          df_2016[df_2016['Country Name'] != 'United States']['gdp'].values.reshape(-1, 1))\n",
    "inputs = np.linspace(1, 2000000000, num=50)\n",
    "predictions = model.predict(inputs.reshape(-1,1))\n",
    "plt.plot(inputs, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce81f7",
   "metadata": {},
   "source": [
    "#### Eliminating Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9040d",
   "metadata": {},
   "source": [
    "##### Removing extreme values helps us see the true patterns and trends in data without distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b78739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# Try reading with skiprows=4, but print columns to verify\n",
    "gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=4)\n",
    "print(\"GDP columns:\", gdp.columns)\n",
    "population = pd.read_csv('N:/ETL/raw_files/population_data.csv', skiprows=4)\n",
    "print(\"Population columns:\", population.columns)\n",
    "\n",
    "# If 'Country Name' is missing, try reading without skiprows or with skiprows=3\n",
    "if 'Country Name' not in gdp.columns:\n",
    "    gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=3)\n",
    "    print(\"GDP columns after skiprows=3:\", gdp.columns)\n",
    "if 'Country Name' not in population.columns:\n",
    "    population = pd.read_csv('N:/ETL/raw_files/population_data.csv', skiprows=3)\n",
    "    print(\"Population columns after skiprows=3:\", population.columns)\n",
    "\n",
    "# If still missing, try reading without skiprows\n",
    "if 'Country Name' not in gdp.columns:\n",
    "    gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv')\n",
    "    print(\"GDP columns after skiprows=0:\", gdp.columns)\n",
    "if 'Country Name' not in population.columns:\n",
    "    population = pd.read_csv('N:/ETL/raw_files/population_data.csv')\n",
    "    print(\"Population columns after skiprows=0:\", population.columns)\n",
    "\n",
    "gdp.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1, errors='ignore')\n",
    "population.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "# Ensure 'Country Name' exists before melting\n",
    "if 'Country Name' in gdp.columns:\n",
    "    gdp_melt = gdp.melt(id_vars=['Country Name'], \n",
    "                        var_name='year', \n",
    "                        value_name='gdp')\n",
    "    # Use back fill and forward fill to fill in missing gdp values\n",
    "    gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby('Country Name')['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
    "else:\n",
    "    raise KeyError(\"Column 'Country Name' not found in GDP data.\")\n",
    "\n",
    "if 'Country Name' in population.columns:\n",
    "    population_melt = population.melt(id_vars=['Country Name'], \n",
    "                                      var_name='year', \n",
    "                                      value_name='population')\n",
    "    # Use back fill and forward fill to fill in missing population values\n",
    "    population_melt['population'] = population_melt.sort_values('year').groupby('Country Name')['population'].fillna(method='ffill').fillna(method='bfill')\n",
    "else:\n",
    "    raise KeyError(\"Column 'Country Name' not found in Population data.\")\n",
    "\n",
    "# merge the population and gdp data together into one data frame\n",
    "df_country = gdp_melt.merge(population_melt, on=('Country Name', 'year'))\n",
    "\n",
    "# filter data for the year 2016\n",
    "df_2016 = df_country[df_country['year'] == '2016']\n",
    "\n",
    "# filter out values that are not countries\n",
    "non_countries = ['World',\n",
    " 'High income',\n",
    " 'OECD members',\n",
    " 'Post-demographic dividend',\n",
    " 'IDA & IBRD total',\n",
    " 'Low & middle income',\n",
    " 'Middle income',\n",
    " 'IBRD only',\n",
    " 'East Asia & Pacific',\n",
    " 'Europe & Central Asia',\n",
    " 'North America',\n",
    " 'Upper middle income',\n",
    " 'Late-demographic dividend',\n",
    " 'European Union',\n",
    " 'East Asia & Pacific (excluding high income)',\n",
    " 'East Asia & Pacific (IDA & IBRD countries)',\n",
    " 'Euro area',\n",
    " 'Early-demographic dividend',\n",
    " 'Lower middle income',\n",
    " 'Latin America & Caribbean',\n",
    " 'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    " 'Latin America & Caribbean (excluding high income)',\n",
    " 'Europe & Central Asia (IDA & IBRD countries)',\n",
    " 'Middle East & North Africa',\n",
    " 'Europe & Central Asia (excluding high income)',\n",
    " 'South Asia (IDA & IBRD)',\n",
    " 'South Asia',\n",
    " 'Arab World',\n",
    " 'IDA total',\n",
    " 'Sub-Saharan Africa',\n",
    " 'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    " 'Sub-Saharan Africa (excluding high income)',\n",
    " 'Middle East & North Africa (excluding high income)',\n",
    " 'Middle East & North Africa (IDA & IBRD countries)',\n",
    " 'Central Europe and the Baltics',\n",
    " 'Pre-demographic dividend',\n",
    " 'IDA only',\n",
    " 'Least developed countries: UN classification',\n",
    " 'IDA blend',\n",
    " 'Fragile and conflict affected situations',\n",
    " 'Heavily indebted poor countries (HIPC)',\n",
    " 'Low income',\n",
    " 'Small states',\n",
    " 'Other small states',\n",
    " 'Not classified',\n",
    " 'Caribbean small states',\n",
    " 'Pacific island small states']\n",
    "\n",
    "# remove non countries from the data\n",
    "df_2016 = df_2016[~df_2016['Country Name'].isin(non_countries)]\n",
    "\n",
    "\n",
    "# plot the data\n",
    "x = list(df_2016['population'])\n",
    "y = list(df_2016['gdp'])\n",
    "text = df_2016['Country Name']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.scatter(x, y)\n",
    "plt.title('GDP vs Population')\n",
    "plt.xlabel('GDP')\n",
    "plt.ylabel('Population')\n",
    "for i, txt in enumerate(text):\n",
    "    ax.annotate(txt, (x[i],y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ead224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tukey_rule(data_frame, column_name):\n",
    "    data = data_frame[column_name]\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    max_value = Q3 + 1.5 * IQR\n",
    "    min_value = Q1 - 1.5 * IQR\n",
    "    \n",
    "    return data_frame[(data_frame[column_name] < max_value) & (data_frame[column_name] > min_value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlier_removed = df_2016.copy()\n",
    "\n",
    "for column in ['population','gdp']:\n",
    "    df_outlier_removed = tukey_rule(df_outlier_removed, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "x = list(df_outlier_removed['population'])\n",
    "y = list(df_outlier_removed['gdp'])\n",
    "text = df_outlier_removed['Country Name']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.scatter(x, y)\n",
    "plt.title('GDP vs Population')\n",
    "plt.xlabel('GDP')\n",
    "plt.ylabel('Population')\n",
    "for i, txt in enumerate(text):\n",
    "    ax.annotate(txt, (x[i],y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3ac830",
   "metadata": {},
   "source": [
    "#### Bringing Numbers to a Common Scale (Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647ff08",
   "metadata": {},
   "source": [
    "##### When data involves very large or small numbers, scaling helps by converting them to a comparable range, enhancing analysis and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Read GDP data and check columns\n",
    "gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=4)\n",
    "if 'Country Name' not in gdp.columns:\n",
    "    gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=3)\n",
    "    if 'Country Name' not in gdp.columns:\n",
    "        gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv')\n",
    "print(\"GDP columns:\", gdp.columns)\n",
    "gdp.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "# Read population data and check columns\n",
    "population = pd.read_csv('N:/ETL/raw_files/population_data.csv', skiprows=4)\n",
    "if 'Country Name' not in population.columns:\n",
    "    population = pd.read_csv('N:/ETL/raw_files/population_data.csv', skiprows=3)\n",
    "    if 'Country Name' not in population.columns:\n",
    "        population = pd.read_csv('N:/ETL/raw_files/population_data.csv')\n",
    "print(\"Population columns:\", population.columns)\n",
    "population.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "# Reshape the data sets so that they are in long format\n",
    "if 'Country Name' in gdp.columns:\n",
    "    gdp_melt = gdp.melt(id_vars=['Country Name'], \n",
    "                        var_name='year', \n",
    "                        value_name='gdp')\n",
    "    # Use back fill and forward fill to fill in missing gdp values\n",
    "    gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby('Country Name')['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
    "else:\n",
    "    raise KeyError(\"Column 'Country Name' not found in GDP data.\")\n",
    "\n",
    "if 'Country Name' in population.columns:\n",
    "    population_melt = population.melt(id_vars=['Country Name'], \n",
    "                                      var_name='year', \n",
    "                                      value_name='population')\n",
    "    # Use back fill and forward fill to fill in missing population values\n",
    "    population_melt['population'] = population_melt.sort_values('year').groupby('Country Name')['population'].fillna(method='ffill').fillna(method='bfill')\n",
    "else:\n",
    "    raise KeyError(\"Column 'Country Name' not found in Population data.\")\n",
    "\n",
    "# merge the population and gdp data together into one data frame\n",
    "df_country = gdp_melt.merge(population_melt, on=('Country Name', 'year'))\n",
    "\n",
    "# filter data for the year 2016\n",
    "df_2016 = df_country[df_country['year'] == '2016']\n",
    "\n",
    "# filter out values that are not countries\n",
    "non_countries = ['World',\n",
    " 'High income',\n",
    " 'OECD members',\n",
    " 'Post-demographic dividend',\n",
    " 'IDA & IBRD total',\n",
    " 'Low & middle income',\n",
    " 'Middle income',\n",
    " 'IBRD only',\n",
    " 'East Asia & Pacific',\n",
    " 'Europe & Central Asia',\n",
    " 'North America',\n",
    " 'Upper middle income',\n",
    " 'Late-demographic dividend',\n",
    " 'European Union',\n",
    " 'East Asia & Pacific (excluding high income)',\n",
    " 'East Asia & Pacific (IDA & IBRD countries)',\n",
    " 'Euro area', 'Early-demographic dividend',\n",
    " 'Lower middle income',\n",
    " 'Latin America & Caribbean',\n",
    " 'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    " 'Latin America & Caribbean (excluding high income)',\n",
    " 'Europe & Central Asia (IDA & IBRD countries)',\n",
    " 'Middle East & North Africa',\n",
    " 'Europe & Central Asia (excluding high income)',\n",
    " 'South Asia (IDA & IBRD)',\n",
    " 'South Asia',\n",
    " 'Arab World',\n",
    " 'IDA total',\n",
    " 'Sub-Saharan Africa',\n",
    " 'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    " 'Sub-Saharan Africa (excluding high income)',\n",
    " 'Middle East & North Africa (excluding high income)',\n",
    " 'Middle East & North Africa (IDA & IBRD countries)',\n",
    " 'Central Europe and the Baltics',\n",
    " 'Pre-demographic dividend',\n",
    " 'IDA only',\n",
    " 'Least developed countries: UN classification',\n",
    " 'IDA blend',\n",
    " 'Fragile and conflict affected situations',\n",
    " 'Heavily indebted poor countries (HIPC)',\n",
    " 'Low income',\n",
    " 'Small states',\n",
    " 'Other small states',\n",
    " 'Not classified',\n",
    " 'Caribbean small states',\n",
    " 'Pacific island small states']\n",
    "\n",
    "# remove non countries from the data\n",
    "df_2016 = df_2016[~df_2016['Country Name'].isin(non_countries)]\n",
    "\n",
    "# show the first ten rows\n",
    "print('first ten rows of data')\n",
    "df_2016.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b704159",
   "metadata": {},
   "source": [
    "#### Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_min_max(data):\n",
    "    minimum = min(data)\n",
    "    maximum = max(data)\n",
    "    return minimum, maximum\n",
    "\n",
    "x_min_max(df_2016['gdp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, x_min, x_max):\n",
    "    # Complete this function\n",
    "    # The input is a single value \n",
    "    # The output is the normalized value\n",
    "    return (x - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer():\n",
    "    # Complete the normalizer class\n",
    "    # The normalizer class receives a dataframe as its only input for initialization\n",
    "    # For example, the data frame might contain gdp and population data in two separate columns\n",
    "    # Follow the TODOs in each section\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        \n",
    "        # complete the init function. \n",
    "        # Assume the dataframe has an unknown number of columns like [['gdp', 'population']] \n",
    "        # iterate through each column calculating the min and max for each column\n",
    "        # append the results to the params attribute list\n",
    "        \n",
    "        # For example, take the gdp column and calculate the minimum and maximum\n",
    "        # Put these results in a list [minimum, maximum]\n",
    "        # Append the list to the params variable\n",
    "        # Then take the population column and do the same\n",
    "        \n",
    "        # HINT: You can put your x_min_max() function as part of this class and use it\n",
    "        \n",
    "        self.params = []\n",
    "\n",
    "        for column in dataframe.columns:\n",
    "            self.params.append(x_min_max(dataframe[column]))\n",
    "            \n",
    "    def x_min_max(data):\n",
    "        # complete the x_min_max method\n",
    "        # HINT: You can use the same function defined earlier in the exercise\n",
    "        minimum = min(data)\n",
    "        maximum = max(data)\n",
    "        return minimum, maximum\n",
    "\n",
    "    def normalize_data(self, x):\n",
    "        # complete the normalize_data method\n",
    "        # The function receives a data point as an input and then outputs the normalized version\n",
    "        # For example, if an input data point of [gdp, population] were used. Then the output would\n",
    "        # be the normalized version of the [gdp, population] data point\n",
    "        # Put the results in the normalized variable defined below\n",
    "        \n",
    "        # Assume that the columns in the dataframe used to initialize an object are in the same\n",
    "        # order as this data point x\n",
    "        \n",
    "        # HINT: You cannot use the normalize_data function defined earlier in the exercise.\n",
    "        # You'll need to iterate through the individual values in the x variable        \n",
    "        # Use the params attribute where the min and max values are stored \n",
    "        normalized = []\n",
    "        for i, value in enumerate(x):\n",
    "            x_max = self.params[i][1]\n",
    "            x_min = self.params[i][0]\n",
    "            normalized.append((x[i] - x_min) / (x_max - x_min))\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f62144",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_normalizer = Normalizer(df_2016[['gdp', 'population']])\n",
    "gdp_normalizer.params\n",
    "gdp_normalizer.normalize_data([13424475000000.0, 1300000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e50c60",
   "metadata": {},
   "source": [
    "#### Creating New Insights with Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304675e0",
   "metadata": {},
   "source": [
    "##### We combine or transform existing data into new variables, like calculating GDP per person, to get deeper understanding and better analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# read in the projects data set and do basic wrangling \n",
    "gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=4)\n",
    "if 'Country Name' not in gdp.columns:\n",
    "    gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=3)\n",
    "    if 'Country Name' not in gdp.columns:\n",
    "        gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv')\n",
    "gdp.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "population = pd.read_csv('N:/ETL/raw_files/population_data.csv', skiprows=4)\n",
    "if 'Country Name' not in population.columns:\n",
    "    population = pd.read_csv('N:/ETL/raw_files/population_data.csv', skiprows=3)\n",
    "    if 'Country Name' not in population.columns:\n",
    "        population = pd.read_csv('N:/ETL/raw_files/population_data.csv')\n",
    "population.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "# Reshape the data sets so that they are in long format\n",
    "gdp_melt = gdp.melt(id_vars=['Country Name'], \n",
    "                    var_name='year', \n",
    "                    value_name='gdp')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing gdp values\n",
    "gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby('Country Name')['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "population_melt = population.melt(id_vars=['Country Name'], \n",
    "                                  var_name='year', \n",
    "                                  value_name='population')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing population values\n",
    "population_melt['population'] = population_melt.sort_values('year').groupby('Country Name')['population'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# merge the population and gdp data together into one data frame\n",
    "df_country = gdp_melt.merge(population_melt, on=('Country Name', 'year'))\n",
    "\n",
    "# filter data for the year 2016\n",
    "df_2016 = df_country[df_country['year'] == '2016']\n",
    "\n",
    "# filter out values that are not countries\n",
    "non_countries = ['World',\n",
    " 'High income',\n",
    " 'OECD members',\n",
    " 'Post-demographic dividend',\n",
    " 'IDA & IBRD total',\n",
    " 'Low & middle income',\n",
    " 'Middle income',\n",
    " 'IBRD only',\n",
    " 'East Asia & Pacific',\n",
    " 'Europe & Central Asia',\n",
    " 'North America',\n",
    " 'Upper middle income',\n",
    " 'Late-demographic dividend',\n",
    " 'European Union',\n",
    "  'East Asia & Pacific (excluding high income)',\n",
    " 'East Asia & Pacific (IDA & IBRD countries)',\n",
    " 'Euro area',\n",
    " 'Early-demographic dividend',\n",
    " 'Lower middle income',\n",
    " 'Latin America & Caribbean',\n",
    " 'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    " 'Latin America & Caribbean (excluding high income)',\n",
    " 'Europe & Central Asia (IDA & IBRD countries)',\n",
    " 'Middle East & North Africa',\n",
    " 'Europe & Central Asia (excluding high income)',\n",
    " 'South Asia (IDA & IBRD)',\n",
    " 'South Asia',\n",
    " 'Arab World',\n",
    " 'IDA total',\n",
    " 'Sub-Saharan Africa',\n",
    " 'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    " 'Sub-Saharan Africa (excluding high income)',\n",
    " 'Middle East & North Africa (excluding high income)',\n",
    " 'Middle East & North Africa (IDA & IBRD countries)',\n",
    " 'Central Europe and the Baltics',\n",
    " 'Pre-demographic dividend',\n",
    " 'IDA only',\n",
    " 'Least developed countries: UN classification',\n",
    " 'IDA blend',\n",
    " 'Fragile and conflict affected situations',\n",
    " 'Heavily indebted poor countries (HIPC)',\n",
    " 'Low income',\n",
    " 'Small states',\n",
    " 'Other small states',\n",
    " 'Not classified',\n",
    " 'Caribbean small states',\n",
    " 'Pacific island small states']\n",
    "\n",
    "# remove non countries from the data\n",
    "df_2016 = df_2016[~df_2016['Country Name'].isin(non_countries)]\n",
    "df_2016.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['gdppercapita'] = df_2016['gdp'] / df_2016['population']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d5d05",
   "metadata": {},
   "source": [
    "#### Saving the Final Data (Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca79fc",
   "metadata": {},
   "source": [
    "##### After cleaning and combining, we store the prepared data in files and databases so it can be used easily for reports, sharing, or further research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fcd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# read in the projects data set and do basic wrangling \n",
    "gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=4)\n",
    "population = pd.read_csv('N:/ETL/raw_files/population_data.csv', skiprows=4)\n",
    "\n",
    "# Check and adjust columns for GDP\n",
    "if 'Country Name' not in gdp.columns:\n",
    "    gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv', skiprows=3)\n",
    "    if 'Country Name' not in gdp.columns:\n",
    "        gdp = pd.read_csv('N:/ETL/raw_files/gdp_data.csv')\n",
    "if 'Country Code' not in gdp.columns:\n",
    "    gdp['Country Code'] = None  # Add a placeholder if missing\n",
    "\n",
    "gdp.drop(['Unnamed: 62', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "# Check and adjust columns for Population\n",
    "if 'Country Name' not in population.columns:\n",
    "    population = pd.read_csv('N:/ETL/raw_files/population_data.csv', skiprows=3)\n",
    "    if 'Country Name' not in population.columns:\n",
    "        population = pd.read_csv('N:/ETL/raw_files/population_data.csv')\n",
    "if 'Country Code' not in population.columns:\n",
    "    population['Country Code'] = None  # Add a placeholder if missing\n",
    "\n",
    "population.drop(['Unnamed: 62', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "# Reshape the data sets so that they are in long format\n",
    "gdp_melt = gdp.melt(id_vars=['Country Name', 'Country Code'], \n",
    "                    var_name='year', \n",
    "                    value_name='gdp')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing gdp values\n",
    "gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby(['Country Name', 'Country Code'])['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "population_melt = population.melt(id_vars=['Country Name', 'Country Code'], \n",
    "                                  var_name='year', \n",
    "                                  value_name='population')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing population values\n",
    "population_melt['population'] = population_melt.sort_values('year').groupby(['Country Name', 'Country Code'])['population'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# merge the population and gdp data together into one data frame\n",
    "df_indicator = gdp_melt.merge(population_melt, on=('Country Name', 'Country Code', 'year'))\n",
    "\n",
    "# filter out values that are not countries\n",
    "non_countries = ['World',\n",
    " 'High income',\n",
    " 'OECD members',\n",
    " 'Post-demographic dividend',\n",
    " 'IDA & IBRD total',\n",
    " 'Low & middle income',\n",
    " 'Middle income',\n",
    " 'IBRD only',\n",
    " 'East Asia & Pacific',\n",
    " 'Europe & Central Asia',\n",
    " 'North America',\n",
    " 'Upper middle income',\n",
    " 'Late-demographic dividend',\n",
    " 'European Union',\n",
    " 'East Asia & Pacific (excluding high income)',\n",
    " 'East Asia & Pacific (IDA & IBRD countries)',\n",
    " 'Euro area',\n",
    " 'Early-demographic dividend',\n",
    " 'Lower middle income',\n",
    " 'Latin America & Caribbean',\n",
    "  'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    " 'Latin America & Caribbean (excluding high income)',\n",
    " 'Europe & Central Asia (IDA & IBRD countries)',\n",
    " 'Middle East & North Africa',\n",
    " 'Europe & Central Asia (excluding high income)',\n",
    " 'South Asia (IDA & IBRD)',\n",
    " 'South Asia',\n",
    " 'Arab World',\n",
    " 'IDA total',\n",
    " 'Sub-Saharan Africa',\n",
    " 'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    " 'Sub-Saharan Africa (excluding high income)',\n",
    " 'Middle East & North Africa (excluding high income)',\n",
    " 'Middle East & North Africa (IDA & IBRD countries)',\n",
    " 'Central Europe and the Baltics',\n",
    " 'Pre-demographic dividend',\n",
    " 'IDA only',\n",
    " 'Least developed countries: UN classification',\n",
    " 'IDA blend',\n",
    " 'Fragile and conflict affected situations',\n",
    " 'Heavily indebted poor countries (HIPC)',\n",
    " 'Low income',\n",
    " 'Small states',\n",
    " 'Other small states',\n",
    " 'Not classified',\n",
    " 'Caribbean small states',\n",
    " 'Pacific island small states']\n",
    "\n",
    "# remove non countries from the data\n",
    "df_indicator  = df_indicator[~df_indicator['Country Name'].isin(non_countries)]\n",
    "df_indicator.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_indicator.columns = ['countryname', 'countrycode', 'year', 'gdp', 'population']\n",
    "\n",
    "# output the first few rows of the data frame\n",
    "df_indicator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ead03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycountry\n",
    "from pycountry import countries\n",
    "\n",
    "# read in the projects data set with all columns type string\n",
    "df_projects = pd.read_csv('N:/ETL/raw_files/projects_data.csv', dtype=str)\n",
    "df_projects.drop(['Unnamed: 56'], axis=1, inplace=True)\n",
    "\n",
    "df_projects['countryname'] = df_projects['countryname'].str.split(';').str.get(0)\n",
    "\n",
    "# set up the libraries and variables\n",
    "from collections import defaultdict\n",
    "country_not_found = [] # stores countries not found in the pycountry library\n",
    "project_country_abbrev_dict = defaultdict(str) # set up an empty dictionary of string values\n",
    "\n",
    "# iterate through the country names in df_projects. \n",
    "# Create a dictionary mapping the country name to the alpha_3 ISO code\n",
    "for country in df_projects['countryname'].drop_duplicates().sort_values():\n",
    "    try: \n",
    "        # look up the country name in the pycountry library\n",
    "        # store the country name as the dictionary key and the ISO-3 code as the value\n",
    "        project_country_abbrev_dict[country] = countries.lookup(country).alpha_3\n",
    "    except:\n",
    "        # If the country name is not in the pycountry library, then print out the country name\n",
    "        # And store the results in the country_not_found list\n",
    "        country_not_found.append(country)\n",
    "        \n",
    "# run this code cell to load the dictionary\n",
    "\n",
    "country_not_found_mapping = {'Co-operative Republic of Guyana': 'GUY',\n",
    "             'Commonwealth of Australia':'AUS',\n",
    "             'Democratic Republic of Sao Tome and Prin':'STP',\n",
    "             'Democratic Republic of the Congo':'COD',\n",
    "             'Democratic Socialist Republic of Sri Lan':'LKA',\n",
    "             'East Asia and Pacific':'EAS',\n",
    "             'Europe and Central Asia': 'ECS',\n",
    "             'Islamic  Republic of Afghanistan':'AFG',\n",
    "             'Latin America':'LCN',\n",
    "              'Caribbean':'LCN',\n",
    "             'Macedonia':'MKD',\n",
    "             'Middle East and North Africa':'MEA',\n",
    "             'Oriental Republic of Uruguay':'URY',\n",
    "             'Republic of Congo':'COG',\n",
    "             \"Republic of Cote d'Ivoire\":'CIV',\n",
    "             'Republic of Korea':'KOR',\n",
    "             'Republic of Niger':'NER',\n",
    "             'Republic of Kosovo':'XKX',\n",
    "             'Republic of Rwanda':'RWA',\n",
    "              'Republic of The Gambia':'GMB',\n",
    "              'Republic of Togo':'TGO',\n",
    "              'Republic of the Union of Myanmar':'MMR',\n",
    "              'Republica Bolivariana de Venezuela':'VEN',\n",
    "              'Sint Maarten':'SXM',\n",
    "              \"Socialist People's Libyan Arab Jamahiriy\":'LBY',\n",
    "              'Socialist Republic of Vietnam':'VNM',\n",
    "              'Somali Democratic Republic':'SOM',\n",
    "              'South Asia':'SAS',\n",
    "              'St. Kitts and Nevis':'KNA',\n",
    "              'St. Lucia':'LCA',\n",
    "              'St. Vincent and the Grenadines':'VCT',\n",
    "              'State of Eritrea':'ERI',\n",
    "              'The Independent State of Papua New Guine':'PNG',\n",
    "              'West Bank and Gaza':'PSE',\n",
    "              'World':'WLD'}\n",
    "\n",
    "project_country_abbrev_dict.update(country_not_found_mapping)\n",
    "\n",
    "df_projects['countrycode'] = df_projects['countryname'].apply(lambda x: project_country_abbrev_dict[x])\n",
    "\n",
    "df_projects['boardapprovaldate'] = pd.to_datetime(df_projects['boardapprovaldate'])\n",
    "\n",
    "df_projects['year'] = df_projects['boardapprovaldate'].dt.year.astype(str).str.slice(stop=4)\n",
    "\n",
    "df_projects['totalamt'] = pd.to_numeric(df_projects['totalamt'].str.replace(',',\"\"))\n",
    "\n",
    "df_projects = df_projects[['id', 'countryname', 'countrycode', 'totalamt', 'year']]\n",
    "\n",
    "df_projects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_projects.merge(df_indicator, how='left', on=['countrycode', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d278d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[(df_merged['year'] == '2017') & (df_merged['countryname_y'] == 'Jordan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59919b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_json('countrydata.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('countrydata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "df_merged.to_sql('merged', con = conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('SELECT * FROM merged WHERE year = \"2017\" AND countrycode = \"BRA\"', con = conn).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ee5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "df_indicator.to_sql('indicator', con = conn, if_exists='replace', index=False)\n",
    "df_projects.to_sql('projects', con = conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('SELECT * FROM projects LEFT JOIN indicator ON \\\n",
    "projects.countrycode = indicator.countrycode AND \\\n",
    "projects.year = indicator.year WHERE \\\n",
    "projects.year = \"2017\" AND projects.countrycode = \"BRA\"', con = conn).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ec1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
